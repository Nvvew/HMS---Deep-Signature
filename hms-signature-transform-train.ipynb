{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Description\n### The notebook is based on the excellent version of [HMS Resnet1d GRU Train - 1 / 5 Dataset](https://www.kaggle.com/code/konstantinboyko/hms-resnet1d-gru-train-1-5-dataset)","metadata":{}},{"cell_type":"markdown","source":"# Library","metadata":{}},{"cell_type":"code","source":"!pip install signatory==1.2.6.1.9.0 --no-cache-dir --force-reinstall","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport gc\nimport sys\nimport math\nimport time\nimport random\nimport datetime as dt\nimport numpy as np\nimport pandas as pd\nimport wandb\nimport signatory\n\nfrom glob import glob\nfrom pathlib import Path\nfrom typing import Dict, List, Union\nimport scipy.signal as scisig\nfrom scipy.signal import butter, lfilter, freqz\nfrom matplotlib import pyplot as plt\nfrom tqdm.auto import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD, AdamW\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import (\n    ReduceLROnPlateau,\n    OneCycleLR,\n    CosineAnnealingLR,\n    CosineAnnealingWarmRestarts,\n)\nfrom torch.optim.optimizer import Optimizer\nfrom sklearn.model_selection import GroupKFold\n\n#import cupy as cp\n#import cupyx.scipy.signal as cpsig\n\nsys.path.append(\"/kaggle/input/kaggle-kl-div\")\nimport kaggle_kl_div\n\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n\ndevice = torch.device(\"cuda\")\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n\n!cat /etc/os-release | grep -oP \"PRETTY_NAME=\\\"\\K([^\\\"]*)\"\nprint(f\"BUILD_DATE={os.environ['BUILD_DATE']}, CONTAINER_NAME={os.environ['CONTAINER_NAME']}\")\n\ntry:\n    print(\n        f\"PyTorch Version:{torch.__version__}, CUDA is available:{torch.cuda.is_available()}, Version CUDA:{torch.version.cuda}\"\n    )\n    print(\n        f\"Device Capability:{torch.cuda.get_device_capability()}, {torch.cuda.get_arch_list()}\"\n    )\n    print(\n        f\"CuDNN Enabled:{torch.backends.cudnn.enabled}, Version:{torch.backends.cudnn.version()}\"\n    )\nexcept Exception:\n    pass\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Directory settings","metadata":{}},{"cell_type":"code","source":"class APP:\n    jupyter = \"ipykernel\" in globals()\n    if not jupyter:\n        try:\n            if \"IPython\" in globals().get(\"__doc__\", \"\"):\n                jupyter = True\n        except Exception as inst:\n            print(inst)\n\n    kaggle = os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\", \"\") != \"\"\n    local = os.environ.get(\"DOCKER_USING\", \"\") == \"LOCAL\"\n    date_time_start = dt.datetime.now()\n    dt_start_ymd_hms = date_time_start.strftime(\"%Y.%m.%d_%H-%M-%S\")\n\n    file_run_path = \"\"\n    if jupyter:\n        try:\n            file_run_path = Path(globals().get(\"__vsc_ipynb_file__\", \"\"))\n        except Exception as inst:\n            print(inst)\n\n    else:\n        try:\n            file_run_path = Path(__file__)\n        except Exception as inst:\n            print(inst)\n\n    file_run_name = file_run_path.stem\n    path_app = file_run_path.parent\n    path_run = Path(os.getcwd())\n    path_out = (\n        Path(\"/kaggle/working\")\n        if kaggle\n        else file_run_path / f\"{file_run_name}_{dt_start_ymd_hms}\"\n    )\n\n\nOUTPUT_DIR = \"./\"\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)\n\nprint(f\"jupyter:{APP.jupyter}, kaggle:{APP.kaggle}, local:{APP.local}\")\nprint(APP.file_run_path)\nprint(APP.path_out)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"code","source":"class CFG:\n    VERSION = '86'\n\n    wandb = False\n    debug = False\n    create_eegs = False\n    apex = True\n    visualize = False\n    save_all_models = True\n\n    if debug:\n        num_workers = 0\n        parallel = False\n    else:\n        num_workers = os.cpu_count()\n        parallel = True\n\n    model_name = \"resnet1d_gru\"\n    # optimizer = \"Adan\"\n    optimizer = \"AdamW\"\n\n    factor = 0.9\n    eps = 1e-6\n    lr = 8e-3\n    min_lr = 1e-6\n\n    batch_size = 64\n    batch_koef_valid = 2\n    batch_scheduler = True\n    weight_decay = 1e-2\n    gradient_accumulation_steps = 1\n    max_grad_norm = 1e7\n\n    fixed_kernel_size = 5\n    # linear_layer_features = 424\n    # kernels = [3, 5, 7, 9]\n    #linear_layer_features = 448  # Full Signal = 10_000\n    #linear_layer_features = 352  # Half Signal = 5_000\n    linear_layer_features = 304   # 1/4, 1/5, 1/6  Signal = 2_000\n    #linear_layer_features = 280  # 1/10  Signal = 1_000\n    kernels = [3, 5, 7, 9, 11]\n    # kernels = [5, 7, 9, 11, 13]\n\n    seq_length = 50  # Second's\n    sampling_rate = 200  # Hz\n    nsamples = seq_length * sampling_rate  # Число семплов 10_000\n    n_split_samples = 5\n    out_samples = nsamples // n_split_samples  # 2_000\n    sample_delta = nsamples - out_samples  # 8000\n    sample_offset = sample_delta // 2\n    multi_validation = False\n\n    train_by_stages = False\n    train_by_folds = True\n\n    # 'GPD', 'GRDA', 'LPD', 'LRDA', 'Other', 'Seizure'\n    n_stages = 2\n    match n_stages:\n        case 1:\n            train_stages = [0]\n            epochs = [100]\n            test_total_eval = 2\n            total_evals_old = [[(2, 3), (6, 29)]]  # Deprecated\n            total_evaluators = [ \n                [   \n                    {'band':(2, 2), 'excl_evals':[]}, \n                    {'band':(6, 28), 'excl_evals':[]},\n                ], \n            ]            \n        case 2:\n            train_stages = [0, 1]\n            epochs = [50, 100]\n            test_total_eval = 0\n            total_evals_old = [[(1, 2),(4, 5)], (6, 29)]  # Deprecated\n            total_evaluators = [ \n                [   \n                    {'band':(3, 3), 'excl_evals':[]},\n                    {'band':(6, 28), 'excl_evals':[]},\n                ], \n                [   \n                    {'band':(1, 2), 'excl_evals':[]}, \n                    {'band':(4, 5), 'excl_evals':[]}, \n                ], \n            ]            \n        case 3:\n            train_stages = [0, 1, 2]\n            epochs = [20, 50, 100]\n            test_total_eval = 0\n            total_evals_old = [(0, 3), (3, 6), (6, 29)]  # Deprecated\n            total_evaluators = [ \n                [   \n                    {'band':(0, 2), 'excl_evals':[]}, \n                ], \n                [   \n                    {'band':(3, 5), 'excl_evals':[]}, \n                ], \n                [   \n                    {'band':(6, 28), 'excl_evals':[]},\n                ], \n            ]            \n    \n    n_fold = 5\n    train_folds = [0, 1, 2, 3, 4]\n    # train_folds = [0]\n\n    patience = 11\n    seed = 2024\n\n    bandpass_filter = {\"low\": 0.5, \"high\": 20, \"order\": 2}\n    rand_filter = {\"probab\": 0.1, \"low\": 10, \"high\": 20, \"band\": 1.0, \"order\": 2}\n    freq_channels = []  # [(8.0, 12.0)]; [(0.5, 4.5)]\n    filter_order = 2\n\n    random_divide_signal = 0.05\n    random_close_zone = 0.05\n    random_common_negative_signal = 0.0\n    random_common_reverse_signal = 0.0\n    random_negative_signal = 0.05\n    random_reverse_signal = 0.05\n\n    log_step = 100  # Шаг отображения тренировки\n    log_show = False\n\n    scheduler = \"CosineAnnealingWarmRestarts\"  # ['ReduceLROnPlateau', 'CosineAnnealingLR', 'CosineAnnealingWarmRestarts','OneCycleLR']\n\n    # CosineAnnealingLR params\n    cosanneal_params = {\n        \"T_max\": 6,\n        \"eta_min\": 1e-5,\n        \"last_epoch\": -1,\n    }\n\n    # ReduceLROnPlateau params\n    reduce_params = {\n        \"mode\": \"min\",\n        \"factor\": 0.2,\n        \"patience\": 4,\n        \"eps\": 1e-6,\n        \"verbose\": True,\n    }\n\n    # CosineAnnealingWarmRestarts params\n    cosanneal_res_params = {\n        \"T_0\": 20,\n        \"eta_min\": 1e-6,\n        \"T_mult\": 1,\n        \"last_epoch\": -1,\n    }\n\n    target_cols = [\n        \"seizure_vote\",\n        \"lpd_vote\",\n        \"gpd_vote\",\n        \"lrda_vote\",\n        \"grda_vote\",\n        \"other_vote\",\n    ]\n\n    pred_cols = [x + \"_pred\" for x in target_cols]\n\n    map_features = [\n        (\"Fp1\", \"T3\"),\n        (\"T3\", \"O1\"),\n        (\"Fp1\", \"C3\"),\n        (\"C3\", \"O1\"),\n        (\"Fp2\", \"C4\"),\n        (\"C4\", \"O2\"),\n        (\"Fp2\", \"T4\"),\n        (\"T4\", \"O2\"),\n        #('Fz', 'Cz'), ('Cz', 'Pz'),\n    ]\n\n    eeg_features = [\"Fp1\", \"T3\", \"C3\", \"O1\", \"Fp2\", \"C4\", \"T4\", \"O2\"]  # 'Fz', 'Cz', 'Pz'\n        # 'F3', 'P3', 'F7', 'T5', 'Fz', 'Cz', 'Pz', 'F4', 'P4', 'F8', 'T6', 'EKG']\n    feature_to_index = {x: y for x, y in zip(eeg_features, range(len(eeg_features)))}\n    simple_features = []  # 'Fz', 'Cz', 'Pz', 'EKG'\n\n    # eeg_features = [row for row in feature_to_index]\n    # eeg_feat_size = len(eeg_features)\n    \n    n_map_features = len(map_features)\n    in_channels = n_map_features + n_map_features * len(freq_channels) + len(simple_features)\n    target_size = len(target_cols)\n\n    path_inp = Path(\"/kaggle/input\")\n    path_src = path_inp / \"hms-harmful-brain-activity-classification/\"\n    file_train = path_src / \"train.csv\"\n    path_train = path_src / \"train_eegs\"\n    file_features_test = path_train / \"100261680.parquet\"\n    file_eeg_specs = path_inp / \"eeg-spectrogram-by-lead-id-unique/eeg_specs.npy\"\n    file_raw_eeg = path_inp / \"brain-eegs/eegs.npy\"\n    #file_raw_eeg = path_inp / \"brain-eegs-plus/eegs.npy\"\n    #file_raw_eeg = path_inp / \"brain-eegs-full/eegs.npy\"\n\n    if APP.kaggle:\n        num_workers = 2\n        parallel = True\n        # GPU_DEVICES = \"auto\"\n\n\n# print(CFG.eeg_feat_size, CFG.in_channels)\nprint(CFG.feature_to_index)\nprint(CFG.eeg_features)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utils","metadata":{}},{"cell_type":"code","source":"def init_logger(log_file=OUTPUT_DIR + \"train.log\"):\n    from logging import getLogger, INFO, FileHandler, Formatter, StreamHandler\n\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=log_file)\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\n\nLOGGER = init_logger()\n\n\ndef asMinutes(s):\n    m = math.floor(s / 60)\n    s -= m * 60\n    return \"%dm %ds\" % (m, s)\n\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s / (percent)\n    rs = es - s\n    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))\n\n\ndef quantize_data(data, classes):\n    mu_x = mu_law_encoding(data, classes)\n    return mu_x  # quantized\n\n\ndef mu_law_encoding(data, mu):\n    mu_x = np.sign(data) * np.log(1 + mu * np.abs(data)) / np.log(mu + 1)\n    return mu_x\n\n\ndef mu_law_expansion(data, mu):\n    s = np.sign(data) * (np.exp(np.abs(data) * np.log(mu + 1)) - 1) / mu\n    return s\n\n\ndef butter_bandpass(lowcut, highcut, fs, order=5):\n    return butter(order, [lowcut, highcut], fs=fs, btype=\"band\")\n\n\ndef butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n    y = lfilter(b, a, data)\n    return y\n\n\ndef butter_lowpass_filter(\n    data, cutoff_freq=20, sampling_rate=CFG.sampling_rate, order=4\n):\n    nyquist = 0.5 * sampling_rate\n    normal_cutoff = cutoff_freq / nyquist\n    b, a = butter(order, normal_cutoff, btype=\"low\", analog=False)\n    filtered_data = lfilter(b, a, data, axis=0)\n    return filtered_data\n\n\ndef denoise_filter(x):\n    # Частота дискретизации и желаемые частоты среза (в Гц).\n    # Отфильтруйте шумный сигнал\n    y = butter_bandpass_filter(x, CFG.lowcut, CFG.highcut, CFG.sampling_rate, order=6)\n    y = (y + np.roll(y, -1) + np.roll(y, -2) + np.roll(y, -3)) / 4\n    y = y[0:-1:4]\n    return y","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Parquet to EEG Signals Numpy Processing","metadata":{}},{"cell_type":"code","source":"def eeg_from_parquet(\n    parquet_path: str, display: bool = False, seq_length=CFG.seq_length\n) -> np.ndarray:\n    \"\"\"\n    Эта функция читает файл паркета и извлекает средние 50 секунд показаний. Затем он заполняет значения NaN\n    со средним значением (игнорируя NaN).\n        :param parquet_path: путь к файлу паркета.\n        :param display: отображать графики ЭЭГ или нет.\n        :return data: np.array формы (time_steps, eeg_features) -> (10_000, 8)\n    \"\"\"\n\n    # Вырезаем среднюю 50 секундную часть\n    eeg = pd.read_parquet(parquet_path, columns=CFG.eeg_features)\n    rows = len(eeg)\n\n    # начало смещения данных, чтобы забрать середину\n    offset = (rows - CFG.nsamples) // 2\n\n    # средние 50 секунд, имеет одинаковое количество показаний слева и справа\n    eeg = eeg.iloc[offset : offset + CFG.nsamples]\n\n    if display:\n        plt.figure(figsize=(10, 5))\n        offset = 0\n\n    # Конвертировать в numpy\n\n    # создать заполнитель той же формы с нулями\n    data = np.zeros((CFG.nsamples, len(CFG.eeg_features)))\n\n    for index, feature in enumerate(CFG.eeg_features):\n        x = eeg[feature].values.astype(\"float32\")  # конвертировать в float32\n\n        # Вычисляет среднее арифметическое вдоль указанной оси, игнорируя NaN.\n        mean = np.nanmean(x)\n        nan_percentage = np.isnan(x).mean()  # percentage of NaN values in feature\n\n        # Заполнение значения Nan\n        # Поэлементная проверка на NaN и возврат результата в виде логического массива.\n        if nan_percentage < 1:  # если некоторые значения равны Nan, но не все\n            x = np.nan_to_num(x, nan=mean)\n        else:  # если все значения — Nan\n            x[:] = 0\n        data[:, index] = x\n\n        if display:\n            if index != 0:\n                offset += x.max()\n            plt.plot(range(CFG.nsamples), x - offset, label=feature)\n            offset -= x.min()\n\n    if display:\n        plt.legend()\n        name = parquet_path.split(\"/\")[-1].split(\".\")[0]\n        plt.yticks([])\n        plt.title(f\"EEG {name}\", size=16)\n        plt.show()\n\n    return data","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class EEGDataset(Dataset):\n    def __init__(\n        self,\n        df: pd.DataFrame,\n        batch_size: int,\n        eegs: Dict[int, np.ndarray],\n        mode: str = \"train\",\n        downsample: int = None,\n        bandpass_filter: Dict[str, Union[int, float]] = None,\n        rand_filter: Dict[str, Union[int, float]] = None,\n    ):\n        self.df = df\n        self.batch_size = batch_size\n        self.mode = mode\n        self.eegs = eegs\n        self.downsample = downsample\n        self.offset = None\n        self.bandpass_filter = bandpass_filter\n        self.rand_filter = rand_filter\n        \n    def __len__(self):\n        \"\"\"\n        Length of dataset.\n        \"\"\"\n        # Обозначает количество пакетов за эпоху\n        return len(self.df)\n\n    def __getitem__(self, index):\n        \"\"\"\n        Get one item.\n        \"\"\"\n        # Сгенерировать один пакет данных\n        X, y_prob = self.__data_generation(index)\n        if self.downsample is not None:\n            X = X[:: self.downsample, :]\n        output = {\n            \"eeg\": torch.tensor(X, dtype=torch.float32),\n            \"labels\": torch.tensor(y_prob, dtype=torch.float32),\n        }\n        return output\n\n    def set_offset(self, offset: int):\n        self.offset = offset\n\n    def __data_generation(self, index):\n        # Генерирует данные, содержащие образцы размера партии\n        X = np.zeros(\n            (CFG.out_samples, CFG.in_channels), dtype=\"float32\"\n        )  # Size=(10000, 14)\n\n        random_divide_signal = False\n        row = self.df.iloc[index]  # Строка Pandas\n        data = self.eegs[row.eeg_id]  # Size=(10000, 8)\n        if CFG.nsamples != CFG.out_samples:\n            if self.mode == \"train\":\n                offset = (CFG.sample_delta * random.randint(0, 1000)) // 1000\n            elif not self.offset is None:\n                offset = self.offset\n            else:\n                offset = CFG.sample_offset\n\n            if self.mode == \"train\" and CFG.random_divide_signal > 0.0 and random.uniform(0.0, 1.0) <= CFG.random_divide_signal:\n                random_divide_signal = True\n                multipliers = [(1, 2), (2, 3), (3, 4), (3, 5)]\n                koef_1, koef_2 = multipliers[random.randint(0, 3)]\n                offset = (koef_1 * offset) // koef_2\n                data = data[offset:offset+(CFG.out_samples * koef_2) // koef_1,:]\n            else:\n                data = data[offset:offset+CFG.out_samples,:]\n\n        reverse_signal = False\n        negative_signal = False\n        if self.mode == \"train\":\n            if CFG.random_common_reverse_signal > 0.0 and random.uniform(0.0, 1.0) <= CFG.random_common_reverse_signal:\n                reverse_signal = True\n            if CFG.random_common_negative_signal > 0.0 and random.uniform(0.0, 1.0) <= CFG.random_common_negative_signal:\n                negative_signal = True\n\n        for i, (feat_a, feat_b) in enumerate(CFG.map_features):\n            if self.mode == \"train\" and CFG.random_close_zone > 0.0 and random.uniform(0.0, 1.0) <= CFG.random_close_zone:\n                continue\n            \n            diff_feat = (\n                data[:, CFG.feature_to_index[feat_a]]\n                - data[:, CFG.feature_to_index[feat_b]]\n            )  # Size=(10000,)\n\n            if self.mode == \"train\":\n                if reverse_signal or CFG.random_reverse_signal > 0.0 and random.uniform(0.0, 1.0) <= CFG.random_reverse_signal:\n                    diff_feat = np.flip(diff_feat)\n                if negative_signal or CFG.random_negative_signal > 0.0 and random.uniform(0.0, 1.0) <= CFG.random_negative_signal:\n                    diff_feat = -diff_feat\n\n            if not self.bandpass_filter is None:\n                diff_feat = butter_bandpass_filter(\n                    diff_feat,\n                    self.bandpass_filter[\"low\"],\n                    self.bandpass_filter[\"high\"],\n                    CFG.sampling_rate,\n                    order=self.bandpass_filter[\"order\"],\n                )\n            \n            if random_divide_signal:\n                #diff_feat = cp.asnumpy(cpsig.upfirdn([1.0, 1, 1.0], diff_feat, 2, 3))  # linear interp, rate 2/3\n                diff_feat = scisig.upfirdn([1.0, 1, 1.0], diff_feat, koef_1, koef_2)  # linear interp, rate 2/3\n                diff_feat = diff_feat[0:CFG.out_samples]\n\n            if (\n                self.mode == \"train\"\n                and not self.rand_filter is None\n                and random.uniform(0.0, 1.0) <= self.rand_filter[\"probab\"]\n            ):\n                lowcut = random.randint(\n                    self.rand_filter[\"low\"], self.rand_filter[\"high\"]\n                )\n                highcut = lowcut + self.rand_filter[\"band\"]\n                diff_feat = butter_bandpass_filter(\n                    diff_feat,\n                    lowcut,\n                    highcut,\n                    CFG.sampling_rate,\n                    order=self.rand_filter[\"order\"],\n                )\n\n            X[:, i] = diff_feat\n\n        n = CFG.n_map_features\n        if len(CFG.freq_channels) > 0:\n            for i in range(CFG.n_map_features):\n                diff_feat = X[:, i]\n                for j, (lowcut, highcut) in enumerate(CFG.freq_channels):\n                    band_feat = butter_bandpass_filter(\n                        diff_feat, lowcut, highcut, CFG.sampling_rate, order=CFG.filter_order,  # 6\n                    )\n                    X[:, n] = band_feat\n                    n += 1\n\n        for spml_feat in CFG.simple_features:\n            feat_val = data[:, CFG.feature_to_index[spml_feat]]\n            \n            if not self.bandpass_filter is None:\n                feat_val = butter_bandpass_filter(\n                    feat_val,\n                    self.bandpass_filter[\"low\"],\n                    self.bandpass_filter[\"high\"],\n                    CFG.sampling_rate,\n                    order=self.bandpass_filter[\"order\"],\n                )\n\n            if (\n                self.mode == \"train\"\n                and not self.rand_filter is None\n                and random.uniform(0.0, 1.0) <= self.rand_filter[\"probab\"]\n            ):\n                lowcut = random.randint(\n                    self.rand_filter[\"low\"], self.rand_filter[\"high\"]\n                )\n                highcut = lowcut + self.rand_filter[\"band\"]\n                feat_val = butter_bandpass_filter(\n                    feat_val,\n                    lowcut,\n                    highcut,\n                    CFG.sampling_rate,\n                    order=self.rand_filter[\"order\"],\n                )\n\n            X[:, n] = feat_val\n            n += 1\n            \n        # Обрезать края превышающие значения [-1024, 1024]\n        X = np.clip(X, -1024, 1024)\n\n        # Замените NaN нулем и разделить все на 32\n        X = np.nan_to_num(X, nan=0) / 32.0\n\n        # обрезать полосовым фильтром верхнюю границу в 20 Hz.\n        X = butter_lowpass_filter(X, order=CFG.filter_order)  # 4\n\n        y_prob = np.zeros(CFG.target_size, dtype=\"float32\")  # Size=(6,)\n        if self.mode != \"test\":\n            y_prob = row[CFG.target_cols].values.astype(np.float32)\n\n        return X, y_prob","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Helper functions","metadata":{}},{"cell_type":"code","source":"class KLDivLossWithLogits(nn.KLDivLoss):\n    def __init__(self):\n        super().__init__(reduction=\"batchmean\")\n\n    def forward(self, y, t):\n        y = nn.functional.log_softmax(y, dim=1)\n        loss = super().forward(y, t)\n        return loss\n\n\nclass AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n\ndef seed_torch(seed):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    # torch.backends.cudnn.benchmark = True  # Это опция требует много паямяти GPU\n    # pl.seed_everything(seed)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"markdown","source":"## Resnet1d Block","metadata":{}},{"cell_type":"code","source":"class ResNet_1D_Block(nn.Module):\n    def __init__(\n        self,\n        in_channels,\n        out_channels,\n        kernel_size,\n        stride,\n        padding,\n        downsampling,\n        dilation=1,\n        groups=1,\n        dropout=0.0,\n        pool=True\n    ):\n        super(ResNet_1D_Block, self).__init__()\n\n        self.bn1 = nn.BatchNorm1d(num_features=in_channels)\n        # self.relu = nn.ReLU(inplace=False)\n        # self.relu_1 = nn.PReLU()\n        # self.relu_2 = nn.PReLU()\n        self.relu_1 = nn.Hardswish()\n        self.relu_2 = nn.Hardswish()\n\n        self.dropout = nn.Dropout(p=dropout, inplace=False)\n        self.conv1 = nn.Conv1d(\n            in_channels=in_channels,\n            out_channels=out_channels,\n            kernel_size=kernel_size,\n            stride=stride,\n            padding=padding,\n            dilation=dilation,\n            groups=groups,\n            bias=False,\n        )\n\n        self.bn2 = nn.BatchNorm1d(num_features=out_channels)\n        self.conv2 = nn.Conv1d(\n            in_channels=out_channels,\n            out_channels=out_channels,\n            kernel_size=kernel_size,\n            stride=stride,\n            padding=padding,\n            dilation=dilation,\n            groups=groups,\n            bias=False,\n        )\n\n        self.maxpool = nn.MaxPool1d(\n            kernel_size=2,\n            stride=2,\n            padding=0,\n            dilation=dilation,\n        )\n        self.downsampling = downsampling\n\n    def forward(self, x):\n        identity = x\n        out = self.bn1(x)\n        out = self.relu_1(out)\n        out = self.dropout(out)\n        out = self.conv1(out)\n        out = self.bn2(out)\n        out = self.relu_2(out)\n        out = self.dropout(out)\n        out = self.conv2(out)\n        if pool:\n            out = self.maxpool(out)\n            identity = self.downsampling(x)\n        \n        #print(f'out{out.shape}')\n        #print(f'identity{identity.shape}')\n        out += identity\n        return out","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Signature Transform","metadata":{}},{"cell_type":"code","source":"def sig(x):\n    start_time = time.time()\n    s = []\n    for i in range(1):\n        ss = []\n        t = x\n        for j in range(999):\n            m = signatory.signature(t[:, 2*j:2*(j+1)], depth=2)\n            m = m.unsqueeze(2)\n            ss.append(m)\n        s.append(torch.cat(ss, dim=2))\n    end_time = time.time()\n    #print(end_time-start_time)\n    return torch.cat(s, dim=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Neural Network","metadata":{}},{"cell_type":"code","source":"class EEGNet(nn.Module):\n    def __init__(\n        self,\n        kernels,\n        in_channels,\n        fixed_kernel_size,\n        num_classes,\n        linear_layer_features,\n        dilation=1,\n        groups=1,\n    ):\n        super(EEGNet, self).__init__()\n        self.kernels = kernels\n        self.planes = 24\n        self.parallel_conv = nn.ModuleList()\n        self.in_channels = in_channels\n\n        for i, kernel_size in enumerate(list(self.kernels)):\n            sep_conv = nn.Conv1d(\n                in_channels=in_channels,\n                out_channels=self.planes,\n                kernel_size=(kernel_size),\n                stride=1,\n                padding=0,\n                dilation=dilation,\n                groups=groups,\n                bias=False,\n            )\n            self.parallel_conv.append(sep_conv)\n\n        self.bn1 = nn.BatchNorm1d(num_features=8)\n        #self.relu_1 = nn.ReLU()\n        #self.relu_2 = nn.ReLU()\n        self.relu_1 = nn.SiLU()\n        self.relu_2 = nn.SiLU()\n \n\n        self.conv1 = nn.Conv1d(\n            in_channels=24,\n            out_channels=8,\n            kernel_size=4,\n            stride=4,\n            padding=2,\n            dilation=dilation,\n            groups=groups,\n            bias=False,\n        )\n        \n        self.conv2 = nn.Conv1d(\n            in_channels=72,\n            out_channels=24,\n            kernel_size=5,\n            stride=1,\n            padding=5//2,\n            dilation=dilation,\n            groups=groups,\n            bias=False,\n        )\n        \n        self.block = self._make_resnet_layer(\n            kernel_size=fixed_kernel_size,\n            stride=1,\n            dilation=dilation,\n            groups=groups,\n            padding=fixed_kernel_size//2,\n        )\n        \n        self.block2 = self._make_resnet_layer2(\n            kernel_size=fixed_kernel_size,\n            stride=1,\n            dilation=dilation,\n            groups=groups,\n            padding=fixed_kernel_size//2,\n        )\n \n        self.bn2 = nn.BatchNorm1d(num_features=72)\n        self.avgpool = nn.AvgPool1d(kernel_size=6, stride=6, padding=0)\n\n        self.fc = nn.Linear(in_features=144, out_features=num_classes)\n\n    \n    def _make_resnet_layer(\n        self,\n        kernel_size,\n        stride,\n        dilation=1,\n        groups=1,\n        blocks=9,\n        padding=0,\n        dropout=0.0,\n    ):\n        layers = []\n        downsample = None\n        base_width = self.planes\n\n        for i in range(blocks):\n            downsampling = nn.Sequential(\n                nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n            )\n            layers.append(\n                ResNet_1D_Block(\n                    in_channels=8,\n                    out_channels=8,\n                    kernel_size=kernel_size,\n                    stride=stride,\n                    padding=padding,\n                    downsampling=downsampling,\n                    dilation=dilation,\n                    groups=groups,\n                    dropout=dropout,\n                    pool=False\n                )\n            )\n        return nn.Sequential(*layers)\n    \n    def _make_resnet_layer2(\n        self,\n        kernel_size,\n        stride,\n        dilation=1,\n        groups=1,\n        blocks=6,\n        padding=0,\n        dropout=0.0,\n    ):\n        layers = []\n        downsample = None\n        base_width = self.planes\n\n        for i in range(blocks):\n            downsampling = nn.Sequential(\n                nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n            )\n            layers.append(\n                ResNet_1D_Block(\n                    in_channels=72,\n                    out_channels=72,\n                    kernel_size=kernel_size,\n                    stride=stride,\n                    padding=padding,\n                    downsampling=downsampling,\n                    dilation=dilation,\n                    groups=groups,\n                    dropout=dropout,\n                )\n            )\n        return nn.Sequential(*layers)\n\n    \n    def augment(self, x):\n        \n        x = x.permute(0, 2, 1)\n        \n        out = self.block(x)\n        out = self.bn1(out)\n        out = self.relu_1(out)\n\n        return out\n\n    def forward(self, x):\n        out = self.augment(x)\n        out = sig(out.permute(0,2,1))\n        out = self.block2(out)\n        out = self.bn2(out)\n        out = self.relu_2(out)\n        out = self.avgpool(out)\n        out = out.reshape(out.shape[0], -1)\n\n        result = self.fc(out)\n            \n        return result","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train func","metadata":{}},{"cell_type":"code","source":"def train_fn(\n    stage, fold, train_loader, model, criterion, optimizer, epoch, scheduler, device\n):\n    model.train()\n\n    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n    losses = AverageMeter()\n    start = end = time.time()\n    global_step = 0\n   \n    for step, batch in tqdm(enumerate(train_loader)):\n        eegs = batch[\"eeg\"].to(device)\n        labels = batch[\"labels\"].to(device)\n        batch_size = labels.size(0)\n       \n        with torch.cuda.amp.autocast(enabled=CFG.apex):\n            y_preds = model(eegs)\n            loss = criterion(F.log_softmax(y_preds, dim=1), labels)\n        \n        \n        if CFG.gradient_accumulation_steps > 1:\n            loss = loss / CFG.gradient_accumulation_steps\n        \n        losses.update(loss.item(), batch_size)\n        print(f\"Loss: {losses.val:.4f}\")\n        \n        scaler.scale(loss).backward()\n \n        grad_norm = torch.nn.utils.clip_grad_norm_(\n            model.parameters(), CFG.max_grad_norm\n        )\n        \n       \n        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n            scaler.step(optimizer)\n            scaler.update()\n            global_step += 1\n            if CFG.batch_scheduler:\n                scheduler.step()\n        end = time.time()\n        \n       \n        if CFG.log_show and (\n            step % CFG.log_step == 0 or step == (len(train_loader) - 1)\n        ):\n            # remain=timeSince(start, float(step + 1) / len(train_loader))\n            LOGGER.info(\n                f\"Epoch {epoch+1} [{step}/{len(train_loader)}] Loss: {losses.val:.4f} Loss Avg:{losses.avg:.4f}\"\n            )\n            # \"Elapsed {remain:s} Grad: {grad_norm:.4f}  LR: {cheduler.get_lr()[0]:.8f}\"\n\n        if CFG.wandb:\n            wandb.log(\n                {\n                    f\"[fold{fold}] loss\": losses.val,\n                    f\"[fold{fold}] lr\": scheduler.get_lr()[0],\n                }\n            )\n    return losses.avg","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Valid func","metadata":{}},{"cell_type":"code","source":"def valid_fn(stage, epoch, valid_loader, model, criterion, device):\n    losses = AverageMeter()\n    model.eval()\n    preds = []\n    targets = []\n    start = end = time.time()\n\n    for step, batch in enumerate(valid_loader):\n        eegs = batch[\"eeg\"].to(device)\n        labels = batch[\"labels\"].to(device)\n        batch_size = labels.size(0)\n\n        with torch.no_grad():\n            y_preds = model(eegs)\n            loss = criterion(F.log_softmax(y_preds, dim=1), labels)\n\n        if CFG.gradient_accumulation_steps > 1:\n            loss = loss / CFG.gradient_accumulation_steps\n\n        losses.update(loss.item(), batch_size)\n        preds.append(nn.Softmax(dim=1)(y_preds).to(\"cpu\").numpy())\n        targets.append(labels.to(\"cpu\").numpy())\n        end = time.time()\n\n        if CFG.log_show and (\n            step % CFG.log_step == 0 or step == (len(valid_loader) - 1)\n        ):\n            # remain=timeSince(start, float(step + 1) / len(valid_loader))\n            LOGGER.info(\n                f\"Epoch {epoch+1} VALIDATION: [{step}/{len(valid_loader)}] Val Loss: {losses.val:.4f} Val Loss Avg: {losses.avg:.4f}\"\n            )\n            # Elapsed {remain:s}\n\n    predictions = np.concatenate(preds)\n    targets = np.concatenate(targets)\n\n    return losses.avg, predictions","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Build Optimizer","metadata":{}},{"cell_type":"code","source":"def build_optimizer(cfg, model, device, epochs, num_batches_per_epoch):\n    lr = cfg.lr\n    # lr = default_configs[\"lr\"]\n    if cfg.optimizer == \"SAM\":\n        base_optimizer = (\n            torch.optim.SGD\n        )  # define an optimizer for the \"sharpness-aware\" update\n        optimizer_model = SAM(\n            model.parameters(),\n            base_optimizer,\n            lr=lr,\n            momentum=0.9,\n            weight_decay=cfg.weight_decay,\n            adaptive=True,\n        )\n    elif cfg.optimizer == \"Ranger21\":\n        optimizer_model = Ranger21(\n            model.parameters(),\n            lr=lr,\n            weight_decay=cfg.weight_decay,\n            num_epochs=epochs,\n            num_batches_per_epoch=num_batches_per_epoch,\n        )\n    elif cfg.optimizer == \"SGD\":\n        optimizer_model = torch.optim.SGD(\n            model.parameters(), lr=lr, weight_decay=cfg.weight_decay, momentum=0.9\n        )\n    elif cfg.optimizer == \"Adam\":\n        optimizer_model = Adam(model.parameters(), lr=lr, weight_decay=CFG.weight_decay)\n    elif cfg.optimizer == \"AdamW\":\n        optimizer_model = AdamW(\n            model.parameters(), lr=lr, weight_decay=CFG.weight_decay\n        )\n    elif cfg.optimizer == \"Lion\":\n        optimizer_model = Lion(model.parameters(), lr=lr, weight_decay=cfg.weight_decay)\n    elif cfg.optimizer == \"Adan\":\n        optimizer_model = Adan(model.parameters(), lr=lr, weight_decay=cfg.weight_decay)\n\n    return optimizer_model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Scheduler","metadata":{}},{"cell_type":"code","source":"def get_scheduler(optimizer, epochs, steps_per_epoch):\n    if CFG.scheduler == \"ReduceLROnPlateau\":\n        scheduler = ReduceLROnPlateau(optimizer, **CFG.reduce_params)\n    elif CFG.scheduler == \"CosineAnnealingLR\":\n        scheduler = CosineAnnealingLR(optimizer, **CFG.cosanneal_params)\n    elif CFG.scheduler == \"CosineAnnealingWarmRestarts\":\n        scheduler = CosineAnnealingWarmRestarts(optimizer, **CFG.cosanneal_res_params)\n    elif CFG.scheduler == \"OneCycleLR\":\n        scheduler = OneCycleLR(\n            optimizer=optimizer,\n            epochs=epochs,\n            pct_start=0.0,\n            steps_per_epoch=steps_per_epoch,\n            max_lr=CFG.lr,\n            div_factor=25,\n            final_div_factor=4.0e-01,\n        )\n    return scheduler","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Loop","metadata":{}},{"cell_type":"code","source":"def train_loop(stage, epochs, folds, fold, directory, prev_dir, eggs):\n    train_folds = folds[folds[\"fold\"] != fold].reset_index(drop=True)\n    valid_folds = folds[folds[\"fold\"] == fold].reset_index(drop=True)\n    valid_labels = valid_folds[CFG.target_cols].values\n\n    train_dataset = EEGDataset(\n        train_folds,\n        batch_size=CFG.batch_size,\n        mode=\"train\",\n        eegs=eggs,\n        bandpass_filter=CFG.bandpass_filter,\n        rand_filter=CFG.rand_filter,\n    )\n        \n    valid_dataset = EEGDataset(\n        valid_folds,\n        batch_size=CFG.batch_size,\n        mode=\"valid\",\n        eegs=eggs,\n        bandpass_filter=CFG.bandpass_filter,\n        #rand_filter=CFG.rand_filter,\n    )\n\n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=CFG.batch_size,\n        shuffle=True,\n        num_workers=CFG.num_workers,\n        pin_memory=True,\n        drop_last=True,\n    )\n\n    valid_loader = DataLoader(\n        valid_dataset,\n        batch_size=CFG.batch_size * CFG.batch_koef_valid,\n        shuffle=False,\n        num_workers=CFG.num_workers,\n        pin_memory=True,\n        drop_last=False,\n    )\n\n    LOGGER.info(\n        f\"========== stage: {stage} fold: {fold} training {len(train_loader)} / {len(valid_loader)} ==========\"\n    )\n    \n\n    model = EEGNet(\n        kernels=CFG.kernels,\n        in_channels=CFG.in_channels,\n        fixed_kernel_size=CFG.fixed_kernel_size,\n        num_classes=CFG.target_size,\n        linear_layer_features=CFG.linear_layer_features,\n        )\n\n    \n    if stage > 1:\n        model_weight = f\"{prev_dir}{CFG.model_name}_ver-{CFG.VERSION}_stage-{stage-1}_fold-{fold}_best.pth\"\n        checkpoint = torch.load(model_weight, map_location=device)\n        model.load_state_dict(checkpoint[\"model\"])\n\n    model.to(device)\n\n    # CPMP: wrap the model to use all GPUs\n    if CFG.parallel:\n        model = nn.DataParallel(model)\n\n    optimizer = build_optimizer(\n        CFG, model, device, epochs=epochs, num_batches_per_epoch=len(train_loader)\n    )\n    scheduler = get_scheduler(\n        optimizer, epochs=epochs, steps_per_epoch=len(train_loader)\n    )\n    criterion = nn.KLDivLoss(reduction=\"batchmean\")\n\n    best_score = np.inf\n    for epoch in range(epochs):\n        start_time = time.time()\n\n        # train\n        avg_loss = train_fn(\n            stage,\n            fold,\n            train_loader,\n            model,\n            criterion,\n            optimizer,\n            epoch,\n            scheduler,\n            device,\n        )\n\n        # eval\n        valid_dataset.set_offset(CFG.sample_offset)\n        avg_val_loss, predictions = valid_fn(\n            stage,\n            epoch,\n            valid_loader,\n            model,\n            criterion,\n            device,\n        )\n        \n        avg_loss_line = ''\n        if CFG.multi_validation:\n            multi_avg_val_loss = np.zeros(CFG.n_split_samples)\n            start = (2 * CFG.sample_delta) // CFG.n_split_samples\n            finish = (3 * CFG.sample_delta) // CFG.n_split_samples\n            delta = (finish - start) // 5\n            for i in range(CFG.n_split_samples):\n                valid_dataset.set_offset(start)\n                multi_avg_val_loss[i], _ = valid_fn(\n                    stage,\n                    epoch,\n                    valid_loader,\n                    model,\n                    criterion,\n                    device,\n                )\n                avg_loss_line += f\" {multi_avg_val_loss[i]:.4f}\"\n                start += delta\n            avg_loss_line += f\" mean={np.mean(multi_avg_val_loss):.4f}\"\n\n        elapsed = time.time() - start_time\n\n        LOGGER.info(\n            f\"Epoch {epoch+1} Avg Train Loss: {avg_loss:.4f} Avg Valid Loss: {avg_val_loss:.4f} / {avg_loss_line}\"\n        )\n        \n        x_0t.append(avg_loss)\n        x_0v.append(avg_val_loss)\n        #   time: {elapsed:.0f}s\n        if CFG.wandb:\n            wandb.log(\n                {\n                    f\"[fold{fold}] stage\": stage,\n                    f\"[fold{fold}] epoch\": epoch + 1,\n                    f\"[fold{fold}] avg_train_loss\": avg_loss,\n                    f\"[fold{fold}] avg_val_loss\": avg_val_loss,\n                    #f\"[fold{fold}] score\": score,\n                }\n            )\n\n        if CFG.save_all_models:\n            torch.save(\n                {\"model\": model.module.state_dict(), \"predictions\": predictions},\n                f\"{directory}{CFG.model_name}_ver-{CFG.VERSION}_stage-{stage}_fold-{fold}_epoch-{epoch}_val-{avg_val_loss:.4f}_train-{avg_loss:.4f}.pth\",\n            )\n\n        if best_score > avg_val_loss:\n            best_score = avg_val_loss\n            LOGGER.info(f\"Epoch {epoch+1} Save Best Valid Loss: {avg_val_loss:.4f}\")\n            # CPMP: save the original model. It is stored as the module attribute of the DP model.\n            torch.save(\n                {\"model\": model.module.state_dict(), \"predictions\": predictions},\n                f\"{directory}{CFG.model_name}_ver-{CFG.VERSION}_stage-{stage}_fold-{fold}_best.pth\",\n            )\n\n    predictions = torch.load(\n        f\"{directory}{CFG.model_name}_ver-{CFG.VERSION}_stage-{stage}_fold-{fold}_best.pth\",\n        map_location=torch.device(\"cpu\"),\n    )[\"predictions\"]\n\n    # valid_folds[[f\"pred_{c}\" for c in CFG.target_cols]] = predictions\n    valid_folds[CFG.pred_cols] = predictions\n    valid_folds[CFG.target_cols] = valid_labels\n\n    torch.cuda.empty_cache()\n    gc.collect()\n\n    return valid_folds, best_score","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load train data","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(CFG.file_train)\nTARGETS = train.columns[-6:]\nprint(\"Train shape:\", train.shape)\nprint(\"Targets\", list(TARGETS))\n\ntrain[\"total_evaluators\"] = train[CFG.target_cols].sum(axis=1)\n\ntrain_uniq = train.drop_duplicates(subset=[\"eeg_id\"] + list(TARGETS))\n\nprint(f\"There are {train.patient_id.nunique()} patients in the training data.\")\nprint(f\"There are {train.eeg_id.nunique()} EEG IDs in the training data.\")\nprint(f\"There are {train_uniq.shape[0]} unique eeg_id + votes in the training data.\")\n\nif CFG.visualize:\n    train_uniq.eeg_id.value_counts().value_counts().plot(\n        kind=\"bar\",\n        title=f\"Distribution of Count of EEG w Unique Vote: \"\n        f\"{train_uniq.shape[0]} examples\",\n    )\n\ndel train_uniq\n_ = gc.collect()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CFG.visualize:\n    plt.figure(figsize=(10, 6))\n    plt.hist(train[\"total_evaluators\"], bins=10, color=\"blue\", edgecolor=\"black\")\n    plt.title(\"Histogram of Total Evaluators\")\n    plt.xlabel(\"Total Evaluators\")\n    plt.ylabel(\"Frequency\")\n    plt.grid(True)\n    plt.show()\n\ntst_eeg_df = pd.read_parquet(CFG.file_features_test)\ntst_eeg_features = tst_eeg_df.columns\nprint(f\"There are {len(tst_eeg_features)} raw eeg features\")\nprint(list(tst_eeg_features))\ndel tst_eeg_df\n_ = gc.collect()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Split Data","metadata":{}},{"cell_type":"code","source":"# %%time\nall_eeg_specs = np.load(CFG.file_eeg_specs, allow_pickle=True).item()\n\ntrain = train[train[\"label_id\"].isin(all_eeg_specs.keys())].copy()\nprint(train.shape[0])\n\ny_data = train[TARGETS].values + 0.166666667  # Regularization value\ny_data = y_data / y_data.sum(axis=1, keepdims=True)\ntrain[TARGETS] = y_data\n\ntrain[\"target\"] = train[\"expert_consensus\"]\n\ntrain[train['total_evaluators'] == CFG.test_total_eval].groupby(['expert_consensus','total_evaluators']).count()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CFG.test_total_eval > 0:\n    train['key_id'] = range(train.shape[0])\n\n    train_pop_olds = []\n    for total_eval in CFG.total_evals_old:\n        if type(total_eval) is list:\n            pop_idx = (train[\"total_evaluators\"] >= total_eval[0][0]) & (\n                train[\"total_evaluators\"] < total_eval[0][1]\n            ) | (train[\"total_evaluators\"] >= total_eval[1][0]) & (\n                train[\"total_evaluators\"] < total_eval[1][1]\n            )\n        else:\n            pop_idx = (train[\"total_evaluators\"] >= total_eval[0]) & (\n                train[\"total_evaluators\"] < total_eval[1]\n            )\n\n        train_pop = train[pop_idx].copy().reset_index()\n\n        sgkf = GroupKFold(n_splits=CFG.n_fold)\n        train_pop[\"fold\"] = -1\n        for fold_id, (_, val_idx) in enumerate(\n            sgkf.split(train_pop, y=train_pop[\"target\"], groups=train_pop[\"patient_id\"])\n        ):\n            train_pop.loc[val_idx, \"fold\"] = fold_id\n\n        train_pop_olds.append(train_pop)\n        print(train_pop.shape[0])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_pops = []\nfor eval_list in CFG.total_evaluators:\n    result=[]\n    train_pop = train  \n    for eval_dict in eval_list:\n        band = eval_dict['band']\n        pop_idx = (train_pop[\"total_evaluators\"] >= band[0]) \n        pop_idx &= (train_pop[\"total_evaluators\"] <= band[1])\n        for exclude in eval_dict['excl_evals']:\n            pop_idx &= ~(train_pop['expert_consensus'] == exclude)\n            pass\n        result.append(train_pop[pop_idx])\n    train_pop = pd.concat(result).copy().reset_index()\n\n    sgkf = GroupKFold(n_splits=CFG.n_fold)\n    train_pop[\"fold\"] = -1\n    for fold_id, (_, val_idx) in enumerate(\n        sgkf.split(train_pop, y=train_pop[\"target\"], groups=train_pop[\"patient_id\"])\n    ):\n        train_pop.loc[val_idx, \"fold\"] = fold_id\n\n    train_pops.append(train_pop)\n    print(train_pop.shape[0])\n\ntrain_0 = train_pops[0]\ntrain_0[train_0['total_evaluators'] == CFG.test_total_eval].groupby(['expert_consensus','total_evaluators']).count()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CFG.test_total_eval > 0:\n    df_old = train_pop_olds[0].copy(deep=True).set_index(['key_id'], drop=True).drop(columns=['fold'])\n    df_new = train_pops[0].copy(deep=True).set_index(['key_id'], drop=True).drop(columns=['fold'])\n\n    #outer merge the two DataFrames, adding an indicator column called 'Exist'\n    diff_df = pd.merge(df_old, df_new, how='outer', indicator='Exist')\n\n    #find which rows don't exist in both DataFrames\n    diff_df = diff_df.loc[diff_df['Exist'] != 'both']\n    display(diff_df)\n\n    del df_old, df_new, diff_df, train_pop_olds\n    _ = gc.collect()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CFG.visualize:\n    print(\"Pop 1: train unique eeg_id + votes shape:\", train_pops[0].shape)\n    plt.figure(figsize=(10, 6))\n    plt.hist(train[\"total_evaluators\"], bins=10, color=\"blue\", edgecolor=\"black\")\n    plt.title(\"Histogram of Total Evaluators\")\n    plt.xlabel(\"Total Evaluators\")\n    plt.ylabel(\"Frequency\")\n    plt.grid(True)\n    plt.show()\n\ndel all_eeg_specs\n_ = gc.collect()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Deduplicate train EEG id","metadata":{}},{"cell_type":"code","source":"# %%time\nif CFG.create_eegs:\n    all_eegs = {}\n    visualize = 1 if CFG.visualize else 0\n    eeg_ids = train.eeg_id.unique()\n\n    for i, eeg_id in tqdm(enumerate(eeg_ids)):\n\n        # Сохранить ЭЭГ в словаре Python для массивов numpy\n        eeg_path = CFG.path_train / f\"{eeg_id}.parquet\"\n\n        # Вырезаем среднюю 50 секундную часть и заполняем по среднему Nan\n        data = eeg_from_parquet(eeg_path, display=i < visualize)\n        all_eegs[eeg_id] = data\n\n        if i == visualize:\n            if CFG.create_eegs:\n                print(\n                    f\"Processing {train['eeg_id'].nunique()} eeg parquets... \", end=\"\"\n                )\n            else:\n                print(f\"Reading {len(eeg_ids)} eeg NumPys from disk.\")\n                break\n    np.save(\"./eegs\", all_eegs)\n\nelse:\n    all_eegs = np.load(CFG.file_raw_eeg, allow_pickle=True).item()\n\nif CFG.visualize:\n    frequencies = [1, 2, 4, 8, 16][::-1]  # frequencies in Hz\n    x = [all_eegs[eeg_ids[0]][:, 0]]  # select one EEG feature\n\n    for frequency in frequencies:\n        x.append(butter_lowpass_filter(x[0], cutoff_freq=frequency))\n\n    plt.figure(figsize=(12, 8))\n    plt.plot(range(CFG.nsamples), x[0], label=\"without filter\")\n    for k in range(1, len(x)):\n        plt.plot(\n            range(CFG.nsamples),\n            x[k] - k * (x[0].max() - x[0].min()),\n            label=f\"with filter {frequencies[k-1]}Hz\",\n        )\n\n    plt.legend()\n    plt.yticks([])\n    plt.title(\"Butter Low-Pass Filter Examples\", size=18)\n    plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CFG.visualize:\n    train_dataset = EEGDataset(\n        train_pops[0], batch_size=CFG.batch_size, eegs=all_eegs, mode=\"train\"\n    )\n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=CFG.batch_size,\n        shuffle=False,\n        num_workers=CFG.num_workers,\n        pin_memory=True,\n        drop_last=True,\n    )\n    output = train_dataset[0]\n    X, y = output[\"eeg\"], output[\"labels\"]\n    print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n\n    iot = torch.randn(2, CFG.nsamples, CFG.in_channels)  # .cuda()\n    model = EEGNet(\n        kernels=CFG.kernels,\n        in_channels=CFG.in_channels,\n        fixed_kernel_size=CFG.fixed_kernel_size,\n        num_classes=CFG.target_size,\n        linear_layer_features=CFG.linear_layer_features,\n    )\n    output = model(iot)\n    print(output.shape)\n\n    for batch in train_loader:\n        X = batch.pop(\"eeg\")\n        y = batch.pop(\"labels\")\n        for item in range(4):\n            plt.figure(figsize=(20, 4))\n            offset = 0\n            for col in range(X.shape[-1]):\n                if col != 0:\n                    offset -= X[item, :, col].min()\n                plt.plot(\n                    range(CFG.nsamples),\n                    X[item, :, col] + offset,\n                    label=f\"feature {col+1}\",\n                )\n                offset += X[item, :, col].max()\n            tt = f\"{y[col][0]:0.1f}\"\n            for t in y[col][1:]:\n                tt += f\", {t:0.1f}\"\n            plt.title(f\"EEG_Id = {eeg_ids[item]}\\nTarget = {tt}\", size=14)\n            plt.legend()\n            plt.show()\n        break\n\n    del iot, model\n    gc.collect()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Stages","metadata":{}},{"cell_type":"code","source":"def get_score(preds, targets):\n    oof = pd.DataFrame(preds.copy())\n    oof[\"id\"] = np.arange(len(oof))\n    true = pd.DataFrame(targets.copy())\n    true[\"id\"] = np.arange(len(true))\n    cv = kaggle_kl_div.score(solution=true, submission=oof, row_id_column_name=\"id\")\n    return cv\n\n\ndef get_result(result_df):\n    gt = result_df[[\"eeg_id\"] + CFG.target_cols]\n    gt.sort_values(by=\"eeg_id\", inplace=True)\n    gt.reset_index(inplace=True, drop=True)\n    preds = result_df[[\"eeg_id\"] + CFG.pred_cols]\n    preds.columns = [\"eeg_id\"] + CFG.target_cols\n    preds.sort_values(by=\"eeg_id\", inplace=True)\n    preds.reset_index(inplace=True, drop=True)\n    score_loss = get_score(gt[CFG.target_cols], preds[CFG.target_cols])\n    LOGGER.info(f\"Score with best loss weights: {score_loss}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if __name__ == \"__main__\" and CFG.train_by_stages:\n    seed_torch(seed=CFG.seed)\n\n    prev_dir = \"\"\n    for stage in range(len(CFG.total_evaluators)):\n        pop_dir = f\"{OUTPUT_DIR}pop_{stage+1}_weight_oof/\"\n        if not os.path.exists(pop_dir):\n            os.makedirs(pop_dir)\n\n        if stage not in CFG.train_stages:\n            prev_dir = pop_dir\n            continue\n\n        oof_df = pd.DataFrame()\n        scores = []\n        for fold in CFG.train_folds:\n            train_oof_df, score = train_loop(\n                stage=stage + 1,\n                epochs=CFG.epochs[stage],\n                fold=fold,\n                folds=train_pops[stage],\n                directory=pop_dir,\n                prev_dir=prev_dir,\n                eggs=all_eegs,\n            )\n\n            oof_df = pd.concat([oof_df, train_oof_df])\n            scores.append(score)\n\n            LOGGER.info(f\"========== stage: {stage+1} fold: {fold} result ==========\")\n            LOGGER.info(f\"Score with best loss weights stage{stage+1}: {score:.4f}\")\n\n        LOGGER.info(f\"==================== CV ====================\")\n        LOGGER.info(f\"Score with best loss weights: {np.mean(scores):.4f}\")\n\n        oof_df.reset_index(drop=True, inplace=True)\n        oof_df.to_csv(\n            f\"{pop_dir}{CFG.model_name}_oof_df_ver-{CFG.VERSION}_stage-{stage+1}.csv\",\n            index=False,\n        )\n\n        prev_dir = pop_dir\n\n    if CFG.wandb:\n        wandb.finish()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if __name__ == \"__main__\" and CFG.train_by_folds:\n    seed_torch(seed=CFG.seed)\n\n    stages_scores = {i: [] for i in CFG.train_stages}\n    stages_oof_df = {i: pd.DataFrame() for i in CFG.train_stages}\n\n    for fold in CFG.train_folds:\n\n        prev_dir = \"\"\n        for stage in range(len(CFG.total_evaluators)):\n\n            pop_dir = f\"{OUTPUT_DIR}pop_{stage+1}_weight_oof/\"\n            if not os.path.exists(pop_dir):\n                os.makedirs(pop_dir)\n\n            if stage not in CFG.train_stages:\n                prev_dir = pop_dir\n                continue\n\n            train_oof_df, score = train_loop(\n                stage=stage + 1,\n                epochs=CFG.epochs[stage],\n                fold=fold,\n                folds=train_pops[stage],\n                directory=pop_dir,\n                prev_dir=prev_dir,\n                eggs=all_eegs,\n            )\n\n            stages_oof_df[stage] = pd.concat([stages_oof_df[stage], train_oof_df])\n            stages_scores[stage].append(score)\n\n            prev_dir = pop_dir\n\n            LOGGER.info(f\"========== fold: {fold} stage: {stage+1} result ==========\")\n            LOGGER.info(f\"Score with best loss weights stage{stage+1}: {score:.4f}\")\n\n    for stage, scores in stages_scores.items():\n        LOGGER.info(f\"============ CV score with best loss weights ============\")\n        LOGGER.info(f\"Stage {stage}: {np.mean(scores):.4f}\")\n\n    for stage, oof_df in stages_oof_df.items():\n        pop_dir = f\"{OUTPUT_DIR}pop_{stage+1}_weight_oof/\"\n        oof_df.reset_index(drop=True, inplace=True)\n        oof_df.to_csv(\n            f\"{pop_dir}{CFG.model_name}_oof_df_ver-{CFG.VERSION}_stage-{stage+1}.csv\",\n            index=False,\n        )\n\n    if CFG.wandb:\n        wandb.finish()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"# === Pre-process OOF ===\ngt = oof_df[[\"eeg_id\"] + CFG.target_cols]\ngt.sort_values(by=\"eeg_id\", inplace=True)\ngt.reset_index(inplace=True, drop=True)\n\npreds = oof_df[[\"eeg_id\"] + CFG.pred_cols]\npreds.columns = [\"eeg_id\"] + CFG.target_cols\npreds.sort_values(by=\"eeg_id\", inplace=True)\npreds.reset_index(inplace=True, drop=True)\n\ny_trues = gt[CFG.target_cols]\ny_preds = preds[CFG.target_cols]\n\noof = pd.DataFrame(y_preds.copy())\noof[\"id\"] = np.arange(len(oof))\n\ntrue = pd.DataFrame(y_trues.copy())\ntrue[\"id\"] = np.arange(len(true))\n\ncv = kaggle_kl_div.score(solution=true, submission=oof, row_id_column_name=\"id\")\nprint(f\"CV Score with resnet1D_gru Raw EEG = {cv:.4f}\")","metadata":{},"execution_count":null,"outputs":[]}]}